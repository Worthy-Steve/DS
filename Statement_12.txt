# Statement 12
# Preprocess the Alphabet dataset and train a CNN with the architecture using Adam optimizer, 20 epochs, batch size 64, and learning rate 0.001.

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape
from tensorflow.keras.optimizers import Adam
import time

# ðŸ”¹ Step 1: Load dataset
data = pd.read_csv("alphabet_ocr.csv")  # Replace with actual filename

# ðŸ”¹ Step 2: Split features and labels
X = data.iloc[:, :-1].values   # All but last column = pixel values
y = data.iloc[:, -1].values    # Last column = labels (Aâ€“Z)

# ðŸ”¹ Step 3: Encode labels (Aâ€“Z â†’ 0â€“25)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = to_categorical(y_encoded, num_classes=26)

# ðŸ”¹ Step 4: Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ðŸ”¹ Step 5: Reshape features to image format (e.g., 16x16)
X_reshaped = X_scaled.reshape(-1, 16, 16, 1)  # Assuming 16x16 grayscale images or can be 28

# ðŸ”¹ Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)

# ðŸ”¹ Step 7: Build CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(26, activation='softmax'))  # 26 classes (A-Z)

# ðŸ”¹ Step 8: Compile the model
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# ðŸ”¹ Step 9: Train the model
start = time.time()
history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=1)
end = time.time()

# ðŸ”¹ Step 10: Evaluate
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"\nâœ… Training Time: {end - start:.2f} seconds")
print(f"âœ… Test Accuracy: {accuracy * 100:.2f}%")
print(f"âœ… Test Loss: {loss:.4f}")