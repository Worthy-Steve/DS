# Statement 15
# Implement a DNN using RMSprop with learning rates 0.01 and 0.0001 on the Wildfire dataset. Compare training and validation performance.

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import RMSprop

# Step 1: Path to wildfire dataset
train_val_path = r"D:\SEM 6\Deep Learning\Datasets\forest_fire\Training and Validation"

# Step 2: Image preprocessing
img_height, img_width = 64, 64
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)

train_generator = train_datagen.flow_from_directory(
    train_val_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_generator = train_datagen.flow_from_directory(
    train_val_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary',
    subset='validation',
    shuffle=False
)

# Step 3: Build and train model function
def train_model(lr, label):
    model = Sequential([
        Flatten(input_shape=(img_height, img_width, 3)),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    optimizer = RMSprop(learning_rate=lr)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    history = model.fit(train_generator, epochs=10, validation_data=val_generator, verbose=1)
    return history, label

# Step 4: Train with RMSprop using 0.01 and 0.0001
history_001, label_001 = train_model(0.01, "RMSprop (0.01)")
history_0001, label_0001 = train_model(0.0001, "RMSprop (0.0001)")

# Step 5: Plot accuracy
plt.plot(history_001.history['accuracy'], label='Train Acc (0.01)')
plt.plot(history_001.history['val_accuracy'], label='Val Acc (0.01)')
plt.plot(history_0001.history['accuracy'], label='Train Acc (0.0001)')
plt.plot(history_0001.history['val_accuracy'], label='Val Acc (0.0001)')
plt.title('Training vs Validation Accuracy (RMSprop)')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Step 6: Plot loss
plt.plot(history_001.history['loss'], label='Train Loss (0.01)')
plt.plot(history_001.history['val_loss'], label='Val Loss (0.01)')
plt.plot(history_0001.history['loss'], label='Train Loss (0.0001)')
plt.plot(history_0001.history['val_loss'], label='Val Loss (0.0001)')
plt.title('Training vs Validation Loss (RMSprop)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()